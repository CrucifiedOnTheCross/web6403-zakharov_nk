<!DOCTYPE html>
<html lang="ru">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Модель | Oncology CNN</title>
  <link rel="stylesheet" href="./styles.css" />
</head>

<body>
  <header class="site-header">
    <div class="container header-inner">
      <h1 class="site-title"><span class="accent">Oncology</span> CNN</h1>
      <nav class="site-nav" aria-label="Основная навигация">
        <a class="nav-link" href="index.html">Главная</a>
        <a class="nav-link" href="dataset.html">Датасет</a>
        <a class="nav-link active" href="model.html">Модель</a>
        <a class="nav-link" href="results.html">Результаты</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section class="intro">
      <h2>Обучение свёрточных нейронных сетей для классификации медицинских изображений</h2>
      <p>
        В настоящей работе проведён анализ и применение современных архитектур свёрточных нейронных сетей (CNN), а
        именно <strong>ResNet50</strong>, <strong>DenseNet201</strong> и <strong>EfficientNetB0</strong>, в рамках
        парадигмы трансферного обучения для классификации медицинских изображений. Рассмотрены ключевые методологические
        аспекты, включая тонкую настройку моделей, стратегии аугментации данных и использование
        генеративно-состязательных сетей для синтеза дополнительных обучающих примеров.
      </p>
    </section>

    <section>
      <h3>Структура набора данных</h3>
      <p>
        Исходный корпус данных был разделён на обучающую, валидационную и тестовую выборки в соотношении, обеспечивающем
        сохранение исходного распределения классов. Детальная информация о количественном составе выборок представлена
        на странице <a href="dataset.html">Датасет</a>.
      </p>
    </section>

    <section>
      <h3>Обоснование выбора архитектур свёрточных нейронных сетей</h3>
      <h4>ResNet50</h4>
      <p>
        Архитектура <em>Residual Network</em> (ResNet) была предложена для решения проблемы затухания градиента в
        глубоких нейронных сетях. Ключевой инновацией является введение "остаточных связей" (skip connections), которые
        позволяют градиентам беспрепятственно распространяться на более ранние слои. Модель ResNet50, состоящая из 50
        слоёв, использует так называемые «бутылочные» блоки (bottleneck blocks), которые эффективно управляют
        вычислительной сложностью. Эта архитектура хорошо зарекомендовала себя в задачах медицинской визуализации
        благодаря своей способности извлекать сложные иерархические признаки.
      </p>
      <h4>DenseNet201</h4>
      <p>
        <em>Dense Convolutional Network</em> (DenseNet) предлагает альтернативный подход к улучшению информационного
        потока между слоями. В этой архитектуре каждый слой получает на вход карты признаков всех предыдущих слоёв, что
        обеспечивает максимальное переиспользование признаков и снижает общее количество параметров. Модель DenseNet201,
        имеющая 201 слой, является глубокой и эффективной архитектурой, которая отлично подходит для задач, где важны
        тонкие текстурные различия, что часто встречается в медицинской диагностике.
      </p>
      <h4>EfficientNetB0</h4>
      <p>
        Семейство моделей <em>EfficientNet</em> было разработано с целью оптимизации баланса между точностью и
        вычислительными затратами. В основе лежит метод составного масштабирования (compound scaling), который
        равномерно масштабирует глубину, ширину и разрешение сети с помощью единого коэффициента. Базовая модель
        EfficientNetB0 построена на основе мобильных инвертированных блоков (MBConv) с механизмом
        "Squeeze-and-Excitation", который позволяет сети адаптивно взвешивать значимость различных каналов признаков,
        повышая её эффективность.
      </p>
    </section>

    <section>
      <h3>Трансферное обучение и тонкая настройка</h3>
      <p>
        Трансферное обучение является стандартным подходом в медицинской визуализации, позволяющим использовать знания,
        полученные на больших наборах данных, таких как ImageNet, для решения специализированных задач с ограниченным
        количеством данных. Процесс обучения моделей включал следующие этапы:
      </p>
      <ol>
        <li>
          <strong>Инициализация предобученными весами</strong>: Свёрточные слои базовых сетей (ResNet50, DenseNet201,
          EfficientNetB0) были инициализированы весами, полученными в результате обучения на ImageNet.
        </li>
        <li>
          <strong>Обучение классификационной «головы»</strong>: На первом этапе свёрточные слои были "заморожены", и
          обучение проводилось только для добавленных полносвязных слоёв, адаптируя их под классы целевой задачи.
        </li>
        <li>
          <strong>Тонкая настройка (Fine-tuning)</strong>: После начального обучения часть верхних слоёв свёрточной
          основы была "разморожена", и вся модель дообучалась с использованием низкой скорости обучения (low learning
          rate) для более точной адаптации признаков к специфике медицинских изображений.
        </li>
      </ol>
    </section>

    <section>
      <h3>Аугментация данных</h3>
      <p>
        Для повышения робастности моделей и снижения переобучения применялся набор техник аугментации данных.
        Использовались как классические геометрические преобразования (случайные отражения, повороты, сдвиги,
        масштабирование), так и фотометрические (изменение яркости, контрастности и насыщенности). Такой подход
        позволяет искусственно расширить обучающую выборку и научить модель инвариантности к несущественным изменениям в
        изображениях.
      </p>
    </section>

    <section id="stylegan-arch" class="three-column">
      <div>
        <h3>Генерация синтетических данных с помощью StyleGAN2-ADA</h3>
        <p>
          Для дальнейшего расширения обучающей выборки и повышения её разнообразия была использована
          генеративно-состязательная сеть StyleGAN2 с адаптивной аугментацией дискриминатора (ADA). Эта модификация
          StyleGAN2 позволяет эффективно обучать модель на небольших наборах данных, предотвращая переобучение
          дискриминатора за счёт динамической регулировки интенсивности аугментаций.
        </p>
        <figure class="card class-card">
          <img src="./img/stylegan.png" alt="Архитектура StyleGAN2" />
          <figcaption>Схема архитектуры StyleGAN2: синтез через каскад модульных блоков.</figcaption>
        </figure>
        <figure class="card class-card">
          <img src="./img/stylegan2-ada-teaser-1024x252.png" alt="StyleGAN2-ADA: адаптивная аугментация дискриминатора" />
          <figcaption>StyleGAN2‑ADA: адаптивная аугментация для малых датасетов.</figcaption>
        </figure>
      </div>
      <div>
        <h3>Обучение и оценка генеративной модели</h3>
        <p>
          Обучение StyleGAN2-ADA проводилось на целевом наборе медицинских изображений. Качество генерируемых
          синтетических образцов оценивалось с использованием метрики Fréchet Inception Distance (FID), которая измеряет
          расстояние между распределениями признаков реальных и сгенерированных изображений. Низкое значение FID
          свидетельствует о высоком качестве и реалистичности синтетических данных. Сгенерированные изображения,
          прошедшие контроль качества, добавлялись в обучающую выборку, что способствовало улучшению обобщающей
          способности классификационных моделей.
        </p>
        <figure class="card class-card">
          <img src="./img/fakes.png" alt="Примеры синтетических изображений" />
          <figcaption>Синтетические образцы из StyleGAN2-ADA, демонстрирующие разнообразие текстур.</figcaption>
        </figure>
      </div>
      <div>
        <h3>Критерии качества генерации</h3>
        <p>
          Ключевым критерием качества сгенерированных данных является их способность улучшать производительность
          нижестоящей задачи классификации. Помимо количественной оценки с помощью FID, проводилась также экспертная
          визуальная оценка для подтверждения клинической релевантности синтезированных изображений.
        </p>
      </div>
    </section>

    <section>
      <h3>Ансамблирование моделей: от Soft Voting к Стекингу</h3>
      <h4>Простое ансамблирование (Soft Voting)</h4>
      <p>
        Начальный подход к ансамблированию заключался в усреднении вероятностных предсказаний (soft voting) от трёх
        независимых моделей (ResNet50, DenseNet201, EfficientNetB0). Этот метод позволяет снизить дисперсию ошибок и
        повысить общую надёжность предсказаний за счёт компенсации индивидуальных недостатков каждой архитектуры.
      </p>
      <h4>Продвинутое ансамблирование: Стекинг (Stacking)</h4>
      <p>
        Для дальнейшего повышения точности был применён более сложный метод ансамблирования — стекинг (также известный
        как stacked generalization). В отличие от простого усреднения, стекинг включает в себя обучение "мета-модели"
        (meta-learner), которая учится оптимально комбинировать предсказания базовых моделей.
      </p>
      <p>
        Процесс стекинга был организован следующим образом:
      </p>
      <ul>
        <li><strong>Обучение базовых моделей (Level-0):</strong> Модели ResNet50, DenseNet201 и EfficientNetB0 были
          обучены на исходной обучающей выборке.</li>
        <li><strong>Формирование нового набора данных:</strong> Предсказания (вероятности классов), полученные от каждой
          из базовых моделей на валидационной выборке, были использованы в качестве признаков для обучения мета-модели.
        </li>
        <li><strong>Обучение мета-модели (Level-1):</strong> В качестве мета-модели использовалась более простая модель
          (например, логистическая регрессия или градиентный бустинг), которая обучалась на новом наборе данных для
          вынесения окончательного вердикта.</li>
      </ul>
      <p>
        Стекинг позволяет более гибко и эффективно использовать сильные стороны каждой базовой модели, что часто
        приводит к более высокой итоговой точности по сравнению с простым усреднением предсказаний.
      </p>
    </section>
  </main>
</body>

</html>